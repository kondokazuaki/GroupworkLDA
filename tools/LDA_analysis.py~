import os
import argparse
import sys
import numpy as np
import datetime
import json
import gensim
import matplotlib.pyplot as plt
import pickle


#--------------------------------------------------------------
def arg_parse() :
    
    # Parse command line arguments    
    parser = argparse.ArgumentParser(description='Apply LDA analysis to input BoIW corpus')

    # input
    parser.add_argument('--src_corpus', required=True,
                        help="Corpus file (metadata) to be analyzed ( generated by 'BoIW_to_corpus.py' ")

    parser.add_argument('--src_IW_vocabulary_selected', required=False,
                        help="A list of interaction words you want to analyze = portion of the original vocabulary")

    parser.add_argument('--list_num_topic', required=False, default='5,10,15',
                        help="list of topic numbers with comma separation. default=5,10,15")
    
    parser.add_argument('--iteration', required=False, type=int, default=10,
                        help="# of iteration with different initial value for LDA optimization. default=100. For more than 1 iterations, most optimzal result is saved")
    
    parser.add_argument('--BoIW_normalize', action='store_true',
                        help='normalize total frequency in BoIW of each scene')    
    
    parser.add_argument('--module_dir', required=False, default=False,
                        help="A directory in which additional module file(s) exist")

    
    # output
    parser.add_argument('--dst_LDA_path', required=True,
                        help="path for saving LDA analysis results. some additional words and/or extentions will be automatically added at its end to distinguish multiple results")

    parser.add_argument('--check_data', action='store_true',
                        help="save also intermediate result as check data")
    
    
    # others
    parser.add_argument('--verbose', action='store_true',
                        help='control verbose mode')
    

    return parser.parse_args()



#--------------------------------------------------------------
def main() :

    args = arg_parse()
    
    if args.module_dir!=False :
        for path in args.module_dir.split(':') :
            sys.path.append(path)        
    import interaction_word as iw    
    import LDA_utils as utl
    
    path = args.dst_LDA_path.split('.')[0]
    if args.check_data :
        fc = open(path+"_checkdata.dat", mode='w')

    
    # parse # of topics
    num_topics = [ int(i) for i in args.list_num_topic.strip().split(',') ]
                                     
    # load corpus
    with open(args.src_corpus) as f :
        corpus_metadata = json.load(f)
    vocabulary = corpus_metadata['Vocabulary']
    corpus_body_filename = os.path.join(corpus_metadata['Root_path'], corpus_metadata['Corpus_bodydata'])
    corpus_org = np.loadtxt(corpus_body_filename, delimiter=',')
    num_scene = corpus_metadata['#_of_scenes']
    num_IW_type = len(vocabulary)
    
    
    ##################
    # corpus adjustment
    
    # load interaction word vocabulary (selected)
    vocabulary_slct = vocabulary
    if args.src_IW_vocabulary_selected :
        vocabulary_slct, vocabulary_slct_notation = iw.load_vocabulary(args.src_IW_vocabulary_selected)
        if args.verbose : print('Vocabulary(selected) : ', len(vocabulary_slct), ' words\n', vocabulary_slct)
    
    
    # extract selected BoIW
    corpus_slct = corpus_org
    if args.src_IW_vocabulary_selected :
        num_IW_type = len(vocabulary_slct)
        corpus_slct = np.zeros( (num_scene,num_IW_type) )
        for i,IW in enumerate(vocabulary_slct) :
            if IW not in vocabulary :
                print('[Error] selected IW does not exit in the vocabulary')
                sys.exit()
            corpus_slct[:,i] = corpus_org[ :,list(vocabulary.keys()).index(IW) ]
            

    # normalize BoIW
    corpus = corpus_slct.copy()
    if args.BoIW_normalize :
        num_normalize = 1000
        for i in range(num_scene) :
            sum_val = sum(corpus[i,:])
            if sum_val>0 : corpus[i,:] = corpus[i,:] *num_normalize/sum_val


    ##################
    # LDA analysis
        
    # TODO(done): check corpus converter BoIW <-> gensim
    # print(corpus)
    #corpus_gensim = corpus_BoIW2gensim(corpus)
    #print(corpus_gensim)
    #corpusd = corpus_gensim2BoIW(corpus_gensim,num_IW_type)
    #print(corpusd)
    
    # convert BoIW sytle corpus to gensim corpus format
    # see also https://radimrehurek.com/gensim/models/ldamodel.html
    # I do not know why sparse description is required ...
    #corpus  = np.loadtxt('hoge.dat', delimiter=',')
    corpus_gensim = utl.corpus_BoIW2gensim(corpus)
            
    # model training
    models = []
    perplexities = []
    scene_perplexities = []
    topic_dependencies = []   # as max cos similarity among all topic pairs
    model_precisions = []     # as cos similarity between prob. and actual BoIW
    scene_precisions = []
    trained_num_topics = []
    for num_topic in num_topics :
        if num_topic > num_IW_type :
            print('[Warning] topic number less than vocabulary')
            continue
        if args.verbose : print('[Report] training with topic num : ', num_topic)
        model, precision, dep, perplexity  = utl.model_train(corpus_gensim, num_topic, vocabulary_slct, num_learn=args.iteration, random_state_start=1234, think_topic_independency=True)
        models.append(model)
        perplexities.append(perplexity[0])
        scene_perplexities.append(perplexity[1])
        model_precisions.append(precision[0])        
        scene_precisions.append(precision[1])
        topic_dependencies.append(dep)
        trained_num_topics.append(num_topic)
    num_topics = trained_num_topics
        

        
    ##################
    # save results
    if args.verbose : print('[Report] saving results...')

    # meta data
    result = dict()
    result['Generated_date'] = datetime.datetime.now().isoformat()
    result['Root_path'] = os.getcwd()
    result['Scene_duration(sec)'] = corpus_metadata['Scene_duration(sec)']
    result['Scene_step(sec)']     = corpus_metadata['Scene_step(sec)']
    result['#_of_scenes']         = corpus_metadata['#_of_scenes']
    result['Scenes_each_group']   = corpus_metadata['Scenes_each_group']
    result['Vocabulary'] = vocabulary_slct
    result['Analyzed_corpus'] = path+'_analyzed_BoIW.dat'
    result['Topic_nums'] = num_topics
    result['Trained_models']   = [ path+'_model_'+str(num)+'topics.pickle' for num in num_topics ]
    result['Model_precisions']   = model_precisions
    result['Topic_dependencies'] = topic_dependencies
    result['Perplexities'] = perplexities
    result['Scene_fit'] = [ path+'_scene_fit_'+str(num)+'topics.dat' for num in num_topics ]
    result['Model_feature_img'] = path+"_features.jpg"
    with open(path+'.json', mode='w', encoding='utf-8') as f :
        d = json.dumps(result, ensure_ascii=False, indent=2)
        f.write(d)
    
    # analyzed corpus
    np.savetxt(fname=path+'_analyzed_BoIW.dat', X=corpus, fmt='%.2f', delimiter=',', header='GroupWork Activity Corpus = '+str(num_scene)+' scenes x '+str(num_IW_type)+' IWs')

    # trained models
    for i,model in enumerate(models) :
        with open(result['Trained_models'][i], mode='wb') as f:
            pickle.dump(model, f)

    # scene fit
    for i in range(len(num_topics)) :
        data = []
        data.append(scene_precisions[i])
        data.append(scene_perplexities[i])
        data = (np.array(data)).transpose()
        np.savetxt(fname=result['Scene_fit'][i], X=data, fmt='%.2f', delimiter=',', header='Scene precison and perplexity along time')
            
            
    # model precision v. s. topic denpendency along topic nums
    fig,ax = plt.subplots()
    axs = ax.twinx()
    ax.set_xlabel('topic num')
    ax.set_ylim(0,1)
    ax.plot(num_topics, model_precisions, label='model_precision(cos)', color='black')
    ax.plot(num_topics, topic_dependencies, label='topic_dependency(cos)', color='red')    
    axs.set_ylim(0,max(perplexities))
    axs.plot(num_topics, perplexities, label='perplexity', color='blue')
    handler1, label1 = ax.get_legend_handles_labels()
    handler2, label2 = axs.get_legend_handles_labels()
    ax.legend(handler1 + handler2, label1 + label2)
    plt.savefig(result['Model_feature_img'])


    

    sys.exit()
    

    # For check : NMF analysis for checking effective #_of_dimension
    import sklearn
    from sklearn.decomposition import NMF
    RMS =[]
    for i in range(num_IW_type) :
        nmf = NMF(n_components=i+1,max_iter=200)
        nmf.fit(corpus)
        W = nmf.fit_transform(corpus)
        H = nmf.components_
        WH = np.dot(W, H)
        diff = corpus-WH
        rms = np.sqrt(np.square(diff).mean())
        print(i+1, rms)
        RMS.append(rms)
    fig,ax = plt.subplots()
    ax.set_xlabel('topic num')
    ax.set_ylabel('NMF rms')
    ax.set_ylim(0,max(RMS))
    ax.plot(range(1,num_IW_type+1),RMS, color='black')
    plt.savefig('NMF_RMS.jpg')


    

if __name__ == "__main__":

    main()
